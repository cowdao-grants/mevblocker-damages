{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "import requests \n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(csv_file_path)\n",
    "#drop the duplicate transaction in case there is any\n",
    "df_main = df_main.drop_duplicates(subset=[' user_tx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of transaction hash we need to analyse\n",
    "tx_hash_list = [x for x in df_main[' user_tx'].to_list() if pd.notnull(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infuria\n",
    "With this API, we want to get all the inputs necessary to simulate the transaction again later on. Infuria gives us all of these inputs except fot the timestamp of the transaction, which is why we need to use the Etherscan API later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the api key is stored in the config file\n",
    "url = f\"https://mainnet.infura.io/v3/{infura_api_key}\"\n",
    "\n",
    "#Get the infuria response for the first transaction in the list to create a dataframe\n",
    "payload = json.dumps({\n",
    "  \"jsonrpc\": \"2.0\",\n",
    "  \"method\": \"eth_getTransactionByHash\",\n",
    "  \"params\": [tx_hash_list[0]],\n",
    "  \"id\": 1\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "dct = response.json()['result']\n",
    "dct = {k: None if not v else v for k, v in dct.items()} # making sure none of the values are empty\n",
    "df_infuria = pd.DataFrame(dct, index=[0])\n",
    "\n",
    "# get the infuria response for all the other transactions in the list and append the results to the above dataframe\n",
    "for tx_hash in tx_hash_list[1:]:\n",
    "  payload = json.dumps({\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"method\": \"eth_getTransactionByHash\",\n",
    "    \"params\": [tx_hash],\n",
    "    \"id\": 1\n",
    "  })\n",
    "  headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "  }\n",
    "\n",
    "  response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "  if response.ok:\n",
    "    dct = response.json()['result']\n",
    "    dct = {k: None if not v else v for k, v in dct.items()} # making sure none of the values are empty\n",
    "    df_temp = pd.DataFrame(dct, index=[0])\n",
    "    df_infuria = pd.concat([df_infuria, df_temp])\n",
    "    \n",
    "  else: \n",
    "    print(f\"error code {response.status_code} for transaction {tx_hash}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge infuria response to main\n",
    "df_main = df_main.merge(df_infuria, left_on = ' user_tx', right_on = 'hash', how ='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['block_number', ' user_tx', ' fees', 'accessList', 'blockHash',\n",
       "       'blockNumber', 'chainId', 'from', 'gas', 'gasPrice', 'hash', 'input',\n",
       "       'maxFeePerGas', 'maxPriorityFeePerGas', 'nonce', 'r', 's', 'to',\n",
       "       'transactionIndex', 'type', 'v', 'value', 'yParity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etherscan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this API to have the timestamp of the blocks rather than the transactions themselves to reduce the amount of API calls (tx and block time are the same for all tx in the block). We need the timestamp of the transactions because in the Tenderly API, if we do not override the timestamp, then it uses the current time as input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the block numbers of the transactions we want to analyse\n",
    "block_number_list = list(set([x for x in df_main['block_number'].to_list() if pd.notnull(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ehterscan response for the first block in the list to create a dataframe\n",
    "url_eth = f\"https://api.etherscan.io/api?module=block&action=getblockreward&blockno={block_number_list[0]}&apikey={eth_scan_api_key}\"\n",
    "\n",
    "response_eth = requests.request(\"POST\", url_eth)\n",
    "\n",
    "dct_eth = response_eth.json()['result']\n",
    "dct_eth = {k: None if not v else v for k, v in dct_eth.items()} # making sure none of the values are empty\n",
    "df_eth = pd.DataFrame(dct_eth, index=[0])\n",
    "\n",
    "# Get the etherscan responses for the other blocks in the list\n",
    "for block in block_number_list[1:]:\n",
    "  url_temp = f\"https://api.etherscan.io/api?module=block&action=getblockreward&blockno={block}&apikey={eth_scan_api_key}\"\n",
    "  response_temp = requests.request(\"POST\", url_temp)\n",
    "\n",
    "  if response_temp.ok:\n",
    "    dct_temp = response_temp.json()['result']\n",
    "    dct_temp = {k: None if not v else v for k, v in dct_temp.items()} # making sure none of the values are empty\n",
    "    df_temp = pd.DataFrame(dct_temp, index=[0])\n",
    "    df_eth = pd.concat([df_eth, df_temp])\n",
    "    \n",
    "  else: \n",
    "    print(f\"error code {response_temp.status_code} for block {block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eth['blockNumber'] = df_eth['blockNumber'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge eth to main\n",
    "df_main = df_main.merge(df_eth, left_on = 'block_number', right_on = 'blockNumber', how ='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tenderly\n",
    "Here we finally do the simulation. We do it once at the original index position to get the amount of coin transferred originally. Then we do it again at index position 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'X-Access-Key': f'{tenderly_access_token}',\n",
    "    'content-type': 'application/json',\n",
    "}\n",
    "\n",
    "#creating an empty DataFrame for the results\n",
    "columns = ['tx_hash', 'index', 'type', 'raw_amount', 'dollar_value', 'token_contract_address', 'token_name', 'token_dollar_value']\n",
    "df_results = pd.DataFrame(columns = columns)\n",
    "\n",
    "# creating a list of tx hashes where the tenderly api returned nothing\n",
    "tx_hash_problem_list = []\n",
    "\n",
    "#iterating over every row of the main dataframe (one row is one transaction)\n",
    "for index, row in df_main.iterrows():\n",
    "    tx_index_list = [0]\n",
    "    tx_index_list.append(int(row['transactionIndex'], 0))\n",
    "    # for each transaction, simulate twice: once for each index\n",
    "    for tx_index in tx_index_list:\n",
    "        json_data = {\n",
    "        'network_id': int(row['chainId'], 0),\n",
    "        'from': row['from'],\n",
    "        'to': row['to'],\n",
    "        'input': row['input'],\n",
    "        'block_number': row['block_number'],\n",
    "        'transaction_index': tx_index,\n",
    "        'simulation_type': 'quick',\n",
    "        'gas': int(row['gas'], 0),\n",
    "        'value': int(row['value'], 0),\n",
    "        'gas_price': int(row['gasPrice'], 0),\n",
    "        'l1_timestamp': int(row['timeStamp'])\n",
    "        }\n",
    "        \n",
    "        response = requests.post(\n",
    "        'https://api.tenderly.co/api/v1/account/aurelie2/project/cowswap2/simulate',\n",
    "        headers=headers,\n",
    "        json=json_data,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for data in response.json()['transaction']['transaction_info']['asset_changes']:\n",
    "                tx_type = data['type']\n",
    "                tx_raw_amount = data['raw_amount']\n",
    "                tx_dollar_value = data['dollar_value']\n",
    "\n",
    "                #sometimes the following values are empty \n",
    "                try:\n",
    "                    contract_address = data['token_info']['contract_address']\n",
    "                except:\n",
    "                    contract_address = 'None'\n",
    "\n",
    "                try:\n",
    "                    token_name = data['token_info']['name']\n",
    "                except:\n",
    "                    token_name = 'None'\n",
    "                try:\n",
    "                    token_dollar_value = data['token_info']['dollar_value']\n",
    "                except:\n",
    "                    token_dollar_value = 'None'\n",
    "\n",
    "                new_row = {\n",
    "                    'tx_hash' : row['hash'],\n",
    "                    'index' : tx_index, \n",
    "                    'type': tx_type, \n",
    "                    'raw_amount': tx_raw_amount, \n",
    "                    'dollar_value' : tx_dollar_value, \n",
    "                    'token_contract_address': contract_address, \n",
    "                    'token_name': token_name, \n",
    "                    'token_dollar_value': token_dollar_value\n",
    "                    }\n",
    "                df_results = pd.concat([df_results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        except:\n",
    "            example = response.json()\n",
    "            #tx_hash_problem = df_main[df_main['input'] == row['input']]['hash'].values[0]\n",
    "            tx_hash_problem_list.append(row['hash'])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new dataframe with only the transactions where tenderly api returned something.This meanse that there are 2 index values for these good transactions.\n",
    "grouped = df_results.groupby('tx_hash')\n",
    "df_results_good = grouped.filter(lambda x: x['index'].nunique() == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of transactions for which this approach worked: 120 \n",
      "number of transactions for which this approach did not worked: 10 \n",
      "percentage of properly simulated transactions: 92.31%\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'number of transactions for which this approach worked:', df_results_good.tx_hash.nunique(),\n",
    "    \"\\nnumber of transactions for which this approach did not worked:\", len(set(tx_hash_problem_list)),\n",
    "    '\\npercentage of properly simulated transactions:', format(df_results_good.tx_hash.nunique()/(df_results_good.tx_hash.nunique() + len(set(tx_hash_problem_list))), \".2%\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the dollar value of the potential loss for the coins that don't have a dollar value\n",
    "The logic here is \n",
    "- first calculate the difference in dollar if the simulation gives it to us: dollar_value_diff\n",
    "- if we do not have any dollar value for a coin, there will always be a WETH value in the transaction. So we will get the value of the unknown coin based on the WETH value: calulated_dollar_diff\n",
    "- we get the loss for that transaction (dollar_diff) by chosing the dollar_value_diff (if exists) or calulated_dollar_diff (if dollar_value_diff does not exist) \n",
    "- we sum the dollar_diff to calculte the total loss over all transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when the coin appears multiple times, then the amounts are the same anyway\n",
    "df_results_good = df_results_good.groupby(['tx_hash', 'index', 'token_contract_address'], as_index=False).first()\n",
    "df_results_good['dollar_value'] = df_results_good['dollar_value'].astype(float)\n",
    "df_results_good['dollar_value_diff'] = df_results_good.groupby(['tx_hash', 'token_contract_address'])['dollar_value'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first if token name is WETH, then the raw_amount need tos be converted. Every transaction has WETH so I will base the analysis on that \n",
    "df_results_good['raw_amount'] = df_results_good['raw_amount'].astype(float)\n",
    "df_results_good.loc[df_results_good['token_name'] == 'WETH', 'raw_amount'] /= 1e+18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dollar_value(row, df):\n",
    "    if pd.isna(row['dollar_value']):\n",
    "        # Filter the DataFrame to get the subset with the same 'tx_hash' and 'index' values\n",
    "        subset = df[(df['tx_hash'] == row['tx_hash']) & (df['index'] == row['index'])]\n",
    "\n",
    "        if not subset.empty:\n",
    "            # Calculate dollar value based on 'WETH' value if the subset is not empty\n",
    "            weth_row = subset[subset['token_name'] == 'WETH']\n",
    "            if not weth_row.empty:\n",
    "                weth_dollar_value = float(weth_row['dollar_value'].values[0])\n",
    "                unknown_raw_amount = float(row['raw_amount'])\n",
    "                return weth_dollar_value / unknown_raw_amount\n",
    "\n",
    "    # If token_name is not NaN or if the subset is empty, return the original dollar_value\n",
    "    return row['dollar_value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the function to each row\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_results_good.iterrows():\n",
    "    # Call the calculate_dollar_value function and pass the current row and the DataFrame\n",
    "    calculated_value = calculate_dollar_value(row, df_results_good)\n",
    "    \n",
    "    # Update the 'dollar_value' column with the calculated value\n",
    "    df_results_good.at[index, 'dollar_value'] = calculated_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_good = df_results_good.sort_values(by = ['tx_hash', 'index'], ascending = [True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FYI if token_contract_address == 'None', then it's always Ethereum\n",
    "df_results_good['raw_amount'] = df_results_good['raw_amount'].astype(float)\n",
    "df_results_good['raw_amount_diff'] = df_results_good.groupby(['tx_hash', 'token_contract_address'])['raw_amount'].transform(lambda x: x[::-1].diff())\n",
    "df_results_good['calulated_dollar_diff'] = df_results_good['raw_amount_diff'] * df_results_good['dollar_value']\n",
    "df_results_good['dollar_diff'] = np.where(pd.notnull(df_results_good['dollar_value_diff']), df_results_good['dollar_value_diff'], df_results_good['calulated_dollar_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the total potential loss in dollars for the given transactions -495764.49344588537\n"
     ]
    }
   ],
   "source": [
    "print(\"this is the total potential loss in dollars for the given transactions\", df_results_good.dollar_diff.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# export the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop these columns to avoid confusion since the dollar_diff column encompasses these values already\n",
    "df_results_good.drop(columns=['calulated_dollar_diff', 'dollar_value_diff'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_good.to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
